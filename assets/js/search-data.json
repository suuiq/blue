{
  
    
        "post0": {
            "title": "과제 2.1",
            "content": "import pandas as pd ds = pd.read_csv(&#39;buy.csv&#39;, header=0, sep=&quot;,&quot;) ds2 = pd.read_csv(&#39;buy.txt&#39;, header=0, sep=&quot; t&quot;) ds2.head() . id year buy age edu income exp co ad prod . 0 1 | 2013 | 1 | 5 | 3 | 17600 | 8800 | 9.3 | 11.36 | 5.01 | . 1 2 | 2013 | 0 | 4 | 2 | 2500 | 2300 | 10.2 | 0.39 | NaN | . 2 3 | 2013 | 0 | 3 | 1 | 6700 | 5400 | 30.6 | 3.83 | 16.67 | . 3 4 | 2013 | 1 | 2 | 1 | 1900 | 1200 | 24.4 | 1.36 | 3.28 | . 4 5 | 2013 | 0 | 3 | 1 | 2500 | 1900 | 19.7 | 2.78 | 2.15 | . ds2.to_excel(excel_writer=&#39;buy.xlsx&#39;) . bx=pd.read_excel(&#39;buy.xlsx&#39;, header=0) . bx . Unnamed: 0 id year buy age edu income exp co ad prod . 0 0 | 1 | 2013 | 1 | 5 | 3 | 17600 | 8800 | 9.3 | 11.36 | 5.01 | . 1 1 | 2 | 2013 | 0 | 4 | 2 | 2500 | 2300 | 10.2 | 0.39 | NaN | . 2 2 | 3 | 2013 | 0 | 3 | 1 | 6700 | 5400 | 30.6 | 3.83 | 16.67 | . 3 3 | 4 | 2013 | 1 | 2 | 1 | 1900 | 1200 | 24.4 | 1.36 | 3.28 | . 4 4 | 5 | 2013 | 0 | 3 | 1 | 2500 | 1900 | 19.7 | 2.78 | 2.15 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 695 695 | 696 | 2015 | 0 | 2 | 3 | 2000 | 1000 | 4.7 | 0.22 | 0.72 | . 696 696 | 697 | 2015 | 0 | 4 | 2 | 6600 | 5500 | 12.1 | 2.32 | 5.67 | . 697 697 | 698 | 2015 | 1 | 3 | 2 | 2700 | 1400 | 4.6 | 0.26 | 0.98 | . 698 698 | 699 | 2015 | 0 | 4 | 1 | 7700 | 3200 | 8.4 | 2.30 | 4.17 | . 699 699 | 700 | 2015 | 0 | 3 | 1 | 4400 | 3600 | 14.7 | 2.99 | 3.47 | . 700 rows × 11 columns . bx1=bx.drop([&#39;Unnamed: 0&#39;], axis=1) . &#44284;&#51228; 2.2 . import numpy as np . bx1.describe(include=[np.number]) #수치형 변수에 대한 통계값 조회 . id year buy age edu income exp co ad prod . count 700.00000 | 700.000000 | 700.000000 | 700.000000 | 700.000000 | 700.000000 | 700.000000 | 700.000000 | 700.000000 | 699.000000 | . mean 350.50000 | 2013.982857 | 0.261429 | 3.134286 | 1.722857 | 4540.142857 | 3300.428571 | 10.260571 | 1.553457 | 3.059514 | . std 202.21688 | 0.805733 | 0.439727 | 0.941324 | 0.928206 | 3538.478854 | 2458.709046 | 6.827234 | 2.117209 | 3.289702 | . min 1.00000 | 2013.000000 | 0.000000 | 2.000000 | 1.000000 | 1400.000000 | 700.000000 | 0.400000 | 0.010000 | 0.050000 | . 25% 175.75000 | 2013.000000 | 0.000000 | 2.000000 | 1.000000 | 2400.000000 | 1800.000000 | 5.000000 | 0.370000 | 1.045000 | . 50% 350.50000 | 2014.000000 | 0.000000 | 3.000000 | 1.000000 | 3400.000000 | 2500.000000 | 8.600000 | 0.855000 | 1.980000 | . 75% 525.25000 | 2015.000000 | 1.000000 | 4.000000 | 2.000000 | 5425.000000 | 4025.000000 | 14.125000 | 1.905000 | 3.935000 | . max 700.00000 | 2015.000000 | 1.000000 | 5.000000 | 5.000000 | 34600.000000 | 19600.000000 | 41.300000 | 20.560000 | 27.030000 | . bx1[&#39;income&#39;].sum() #해당 컬럼의 값 합계 . 3178100 . bx1[&#39;prod&#39;].count() #해당 컬럼의 null이 아닌 행의 수 . 699 . corr = bx1.corr() print(corr) . id year buy age edu income exp id 1.000000 0.942445 0.048757 0.011800 0.069123 0.049671 0.045514 year 0.942445 1.000000 0.032856 0.004926 0.056763 0.031352 0.035244 buy 0.048757 0.032856 1.000000 -0.122952 0.114676 -0.079666 -0.125810 age 0.011800 0.004926 -0.122952 1.000000 -0.006465 0.434111 0.428769 edu 0.069123 0.056763 0.114676 -0.006465 1.000000 0.236032 0.209925 income 0.049671 0.031352 -0.079666 0.434111 0.236032 1.000000 0.881412 exp 0.045514 0.035244 -0.125810 0.428769 0.209925 0.881412 1.000000 co 0.013810 0.007939 0.389575 -0.006343 0.008838 -0.025973 -0.004734 ad -0.012080 -0.027363 0.244739 0.231991 0.088245 0.565832 0.473203 prod 0.039895 0.021614 0.145627 0.315224 0.165597 0.619980 0.580467 co ad prod id 0.013810 -0.012080 0.039895 year 0.007939 -0.027363 0.021614 buy 0.389575 0.244739 0.145627 age -0.006343 0.231991 0.315224 edu 0.008838 0.088245 0.165597 income -0.025973 0.565832 0.619980 exp -0.004734 0.473203 0.580467 co 1.000000 0.501732 0.584953 ad 0.501732 1.000000 0.633053 prod 0.584953 0.633053 1.000000 . id,year : 강한 양의 상관관계 | age,income/exp : 보통의 양의 상관관계 | income,exp : 강한 양의 상관관계 | income,ad : 보통의 양의 상관관계 | income,prod : 보통의 양의 상관관계 | co,ad/prod : 보통의 양의 상관관계 ##### 기재한 것 이외에는 약한 상관관계를 가지고 있음, 상관계수의 절댓값이 높을수록 두 변수간의 관계성이 높다. | . &#44284;&#51228; 2.3 . df=pd.DataFrame(np.random.randn(5, 5), columns=[&#39;C1&#39;, &#39;C2&#39;, &#39;C3&#39;,&#39;C4&#39;,&#39;C5&#39;]) . df . C1 C2 C3 C4 C5 . 0 -0.795893 | 0.320761 | 0.368385 | -1.815973 | 1.297452 | . 1 -0.040924 | -0.257711 | -0.119432 | 1.223744 | 0.366901 | . 2 0.576952 | 0.257060 | 0.030175 | 1.016484 | 0.314021 | . 3 -0.995405 | 0.055941 | -0.377488 | -0.105724 | 0.485220 | . 4 -1.223964 | 1.305234 | -0.751024 | -2.824316 | 1.191420 | . df.loc[1,[&#39;C1&#39;,&#39;C3&#39;,&#39;C4&#39;]]=np.nan df.loc[4,[&#39;C2&#39;]]=np.nan . df . C1 C2 C3 C4 C5 . 0 -0.795893 | 0.320761 | 0.368385 | -1.815973 | 1.297452 | . 1 NaN | -0.257711 | NaN | NaN | 0.366901 | . 2 0.576952 | 0.257060 | 0.030175 | 1.016484 | 0.314021 | . 3 -0.995405 | 0.055941 | -0.377488 | -0.105724 | 0.485220 | . 4 -1.223964 | NaN | -0.751024 | -2.824316 | 1.191420 | . df.dropna(thresh = 3) . C1 C2 C3 C4 C5 . 0 -0.795893 | 0.320761 | 0.368385 | -1.815973 | 1.297452 | . 2 0.576952 | 0.257060 | 0.030175 | 1.016484 | 0.314021 | . 3 -0.995405 | 0.055941 | -0.377488 | -0.105724 | 0.485220 | . 4 -1.223964 | NaN | -0.751024 | -2.824316 | 1.191420 | . df.dropna(axis=1) . C5 . 0 1.297452 | . 1 0.366901 | . 2 0.314021 | . 3 0.485220 | . 4 1.191420 | . df.mean() . C1 -0.609577 C2 0.094013 C3 -0.182488 C4 -0.932382 C5 0.731003 dtype: float64 . df.fillna(df.mean()) . C1 C2 C3 C4 C5 . 0 -0.795893 | 0.320761 | 0.368385 | -1.815973 | 1.297452 | . 1 -0.609577 | -0.257711 | -0.182488 | -0.932382 | 0.366901 | . 2 0.576952 | 0.257060 | 0.030175 | 1.016484 | 0.314021 | . 3 -0.995405 | 0.055941 | -0.377488 | -0.105724 | 0.485220 | . 4 -1.223964 | 0.094013 | -0.751024 | -2.824316 | 1.191420 | . &#44284;&#51228; 2.4 . bx1 . id year buy age edu income exp co ad prod . 0 1 | 2013 | 1 | 5 | 3 | 17600 | 8800 | 9.3 | 11.36 | 5.01 | . 1 2 | 2013 | 0 | 4 | 2 | 2500 | 2300 | 10.2 | 0.39 | NaN | . 2 3 | 2013 | 0 | 3 | 1 | 6700 | 5400 | 30.6 | 3.83 | 16.67 | . 3 4 | 2013 | 1 | 2 | 1 | 1900 | 1200 | 24.4 | 1.36 | 3.28 | . 4 5 | 2013 | 0 | 3 | 1 | 2500 | 1900 | 19.7 | 2.78 | 2.15 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 695 696 | 2015 | 0 | 2 | 3 | 2000 | 1000 | 4.7 | 0.22 | 0.72 | . 696 697 | 2015 | 0 | 4 | 2 | 6600 | 5500 | 12.1 | 2.32 | 5.67 | . 697 698 | 2015 | 1 | 3 | 2 | 2700 | 1400 | 4.6 | 0.26 | 0.98 | . 698 699 | 2015 | 0 | 4 | 1 | 7700 | 3200 | 8.4 | 2.30 | 4.17 | . 699 700 | 2015 | 0 | 3 | 1 | 4400 | 3600 | 14.7 | 2.99 | 3.47 | . 700 rows × 10 columns . b=bx1[bx1.year!=2015] . b_=b[b.buy==1] . b_ . id year buy age edu income exp co ad prod . 0 1 | 2013 | 1 | 5 | 3 | 17600 | 8800 | 9.3 | 11.36 | 5.01 | . 3 4 | 2013 | 1 | 2 | 1 | 1900 | 1200 | 24.4 | 1.36 | 3.28 | . 6 7 | 2013 | 1 | 3 | 2 | 4100 | 4100 | 16.4 | 2.92 | 3.81 | . 16 17 | 2013 | 1 | 2 | 2 | 3100 | 2600 | 8.2 | 1.49 | 1.05 | . 23 24 | 2013 | 1 | 2 | 2 | 3600 | 2000 | 12.4 | 3.49 | 0.97 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 463 464 | 2014 | 1 | 2 | 1 | 2100 | 1400 | 8.4 | 1.21 | 0.55 | . 464 465 | 2014 | 1 | 3 | 1 | 4100 | 3600 | 30.7 | 3.00 | 9.59 | . 468 469 | 2014 | 1 | 2 | 3 | 2000 | 2000 | 9.4 | 0.23 | 1.65 | . 475 476 | 2014 | 1 | 2 | 1 | 1400 | 1200 | 9.7 | 0.20 | 1.16 | . 477 478 | 2014 | 1 | 3 | 1 | 3300 | 2600 | 10.3 | 2.50 | 0.90 | . 125 rows × 10 columns . new_b = b_[[&#39;year&#39;, &#39;age&#39;, &#39;edu&#39;, &#39;income&#39;, &#39;exp&#39;]] new_b . year age edu income exp . 0 2013 | 5 | 3 | 17600 | 8800 | . 3 2013 | 2 | 1 | 1900 | 1200 | . 6 2013 | 3 | 2 | 4100 | 4100 | . 16 2013 | 2 | 2 | 3100 | 2600 | . 23 2013 | 2 | 2 | 3600 | 2000 | . ... ... | ... | ... | ... | ... | . 463 2014 | 2 | 1 | 2100 | 1400 | . 464 2014 | 3 | 1 | 4100 | 3600 | . 468 2014 | 2 | 3 | 2000 | 2000 | . 475 2014 | 2 | 1 | 1400 | 1200 | . 477 2014 | 3 | 1 | 3300 | 2600 | . 125 rows × 5 columns . b2=bx1[bx1.year==2015] . newb2=b2[b2.co&gt;10] newb2 . id year buy age edu income exp co ad prod . 488 489 | 2015 | 0 | 2 | 4 | 3200 | 2700 | 17.6 | 2.14 | 3.49 | . 490 491 | 2015 | 0 | 2 | 1 | 2700 | 1300 | 14.4 | 1.02 | 2.87 | . 491 492 | 2015 | 0 | 2 | 2 | 4500 | 5600 | 26.0 | 6.05 | 5.65 | . 493 494 | 2015 | 0 | 4 | 1 | 2600 | 2100 | 10.4 | 0.12 | 2.58 | . 494 495 | 2015 | 1 | 2 | 2 | 2100 | 2200 | 11.4 | 0.78 | 1.62 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 692 693 | 2015 | 0 | 5 | 1 | 5300 | 3100 | 10.5 | 0.84 | 4.72 | . 693 694 | 2015 | 1 | 3 | 1 | 3900 | 3100 | 16.1 | 1.70 | 4.58 | . 694 695 | 2015 | 0 | 3 | 1 | 6800 | 5900 | 10.8 | 1.37 | 5.98 | . 696 697 | 2015 | 0 | 4 | 2 | 6600 | 5500 | 12.1 | 2.32 | 5.67 | . 699 700 | 2015 | 0 | 3 | 1 | 4400 | 3600 | 14.7 | 2.99 | 3.47 | . 98 rows × 10 columns . newb2.describe() . id year buy age edu income exp co ad prod . count 98.000000 | 98.0 | 98.000000 | 98.000000 | 98.000000 | 98.000000 | 98.000000 | 98.00000 | 98.000000 | 98.000000 | . mean 596.612245 | 2015.0 | 0.357143 | 3.142857 | 1.867347 | 4462.244898 | 3259.183673 | 15.90000 | 2.247449 | 4.675612 | . std 62.740282 | 0.0 | 0.481621 | 0.885158 | 0.937619 | 3211.368829 | 2145.810434 | 5.59429 | 1.831431 | 3.869775 | . min 489.000000 | 2015.0 | 0.000000 | 2.000000 | 1.000000 | 1400.000000 | 800.000000 | 10.10000 | 0.120000 | 0.360000 | . 25% 543.500000 | 2015.0 | 0.000000 | 2.000000 | 1.000000 | 2400.000000 | 1925.000000 | 11.85000 | 0.987500 | 2.375000 | . 50% 597.500000 | 2015.0 | 0.000000 | 3.000000 | 2.000000 | 3650.000000 | 2650.000000 | 14.90000 | 1.750000 | 3.620000 | . 75% 648.750000 | 2015.0 | 1.000000 | 4.000000 | 2.000000 | 5250.000000 | 3800.000000 | 18.05000 | 3.027500 | 5.665000 | . max 700.000000 | 2015.0 | 1.000000 | 5.000000 | 4.000000 | 22000.000000 | 13100.000000 | 36.60000 | 9.880000 | 27.030000 | . &#44284;&#51228; 2.5 . bx1 . id year buy age edu income exp co ad prod . 0 1 | 2013 | 1 | 5 | 3 | 17600 | 8800 | 9.3 | 11.36 | 5.01 | . 1 2 | 2013 | 0 | 4 | 2 | 2500 | 2300 | 10.2 | 0.39 | NaN | . 2 3 | 2013 | 0 | 3 | 1 | 6700 | 5400 | 30.6 | 3.83 | 16.67 | . 3 4 | 2013 | 1 | 2 | 1 | 1900 | 1200 | 24.4 | 1.36 | 3.28 | . 4 5 | 2013 | 0 | 3 | 1 | 2500 | 1900 | 19.7 | 2.78 | 2.15 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 695 696 | 2015 | 0 | 2 | 3 | 2000 | 1000 | 4.7 | 0.22 | 0.72 | . 696 697 | 2015 | 0 | 4 | 2 | 6600 | 5500 | 12.1 | 2.32 | 5.67 | . 697 698 | 2015 | 1 | 3 | 2 | 2700 | 1400 | 4.6 | 0.26 | 0.98 | . 698 699 | 2015 | 0 | 4 | 1 | 7700 | 3200 | 8.4 | 2.30 | 4.17 | . 699 700 | 2015 | 0 | 3 | 1 | 4400 | 3600 | 14.7 | 2.99 | 3.47 | . 700 rows × 10 columns . bx60=bx1.sample(frac=0.6) bx60 . id year buy age edu income exp co ad prod . 468 469 | 2014 | 1 | 2 | 3 | 2000 | 2000 | 9.4 | 0.23 | 1.65 | . 576 577 | 2015 | 1 | 3 | 1 | 1700 | 1100 | 3.7 | 0.45 | 0.18 | . 555 556 | 2015 | 0 | 4 | 3 | 1900 | 900 | 10.8 | 0.85 | 1.20 | . 305 306 | 2014 | 0 | 4 | 4 | 4500 | 3100 | 9.8 | 0.97 | 3.44 | . 580 581 | 2015 | 0 | 4 | 1 | 2500 | 1600 | 10.1 | 1.06 | 1.46 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 32 33 | 2013 | 0 | 2 | 3 | 2400 | 2000 | 7.7 | 0.83 | 1.01 | . 455 456 | 2014 | 1 | 4 | 3 | 5500 | 3600 | 16.5 | 1.75 | 7.32 | . 687 688 | 2015 | 0 | 4 | 2 | 11300 | 8100 | 13.2 | 3.19 | 11.72 | . 221 222 | 2013 | 0 | 3 | 1 | 2000 | 1200 | 1.2 | 0.04 | 0.20 | . 508 509 | 2015 | 1 | 2 | 2 | 1700 | 1100 | 27.7 | 2.04 | 2.67 | . 420 rows × 10 columns . bx30=bx1.sample(frac=0.3) bx30 . id year buy age edu income exp co ad prod . 638 639 | 2015 | 0 | 4 | 5 | 19000 | 18800 | 7.8 | 3.16 | 11.66 | . 224 225 | 2013 | 1 | 4 | 1 | 3600 | 3000 | 2.1 | 0.39 | 0.37 | . 2 3 | 2013 | 0 | 3 | 1 | 6700 | 5400 | 30.6 | 3.83 | 16.67 | . 97 98 | 2013 | 0 | 3 | 3 | 4400 | 3500 | 14.7 | 0.45 | 6.02 | . 270 271 | 2014 | 0 | 3 | 1 | 5400 | 3800 | 4.4 | 0.73 | 1.65 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 82 83 | 2013 | 0 | 2 | 1 | 1600 | 900 | 1.2 | 0.08 | 0.11 | . 215 216 | 2013 | 0 | 4 | 1 | 3700 | 2200 | 1.3 | 0.18 | 0.30 | . 290 291 | 2014 | 1 | 3 | 1 | 2900 | 2100 | 13.8 | 1.35 | 2.65 | . 582 583 | 2015 | 0 | 3 | 1 | 3300 | 3300 | 7.0 | 0.40 | 1.91 | . 645 646 | 2015 | 0 | 4 | 1 | 6600 | 3400 | 3.2 | 1.47 | 0.64 | . 210 rows × 10 columns . bx10=bx1.sample(frac=0.1) bx10 . id year buy age edu income exp co ad prod . 153 154 | 2013 | 0 | 2 | 2 | 2200 | 1000 | 11.5 | 0.65 | 1.88 | . 624 625 | 2015 | 0 | 4 | 1 | 24200 | 14900 | 2.6 | 1.64 | 4.66 | . 131 132 | 2013 | 0 | 2 | 2 | 2800 | 1900 | 9.3 | 1.27 | 1.33 | . 694 695 | 2015 | 0 | 3 | 1 | 6800 | 5900 | 10.8 | 1.37 | 5.98 | . 60 61 | 2013 | 0 | 3 | 2 | 4000 | 3200 | 7.2 | 0.18 | 2.70 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 638 639 | 2015 | 0 | 4 | 5 | 19000 | 18800 | 7.8 | 3.16 | 11.66 | . 682 683 | 2015 | 0 | 3 | 1 | 5700 | 3100 | 10.5 | 1.14 | 4.84 | . 514 515 | 2015 | 0 | 4 | 2 | 7500 | 7700 | 23.6 | 9.88 | 7.82 | . 7 8 | 2013 | 0 | 5 | 2 | 5800 | 3800 | 18.4 | 3.08 | 7.59 | . 569 570 | 2015 | 0 | 4 | 1 | 9600 | 5000 | 7.8 | 2.25 | 5.23 | . 70 rows × 10 columns . b13=bx1[bx1.year==2013] b14=bx1[bx1.year==2014] b15=bx1[bx1.year==2015] . b13.sample(frac=0.6) . id year buy age edu income exp co ad prod . 181 182 | 2013 | 0 | 3 | 3 | 2500 | 2000 | 5.7 | 0.34 | 1.08 | . 166 167 | 2013 | 1 | 2 | 1 | 1800 | 1700 | 18.9 | 0.51 | 2.89 | . 107 108 | 2013 | 1 | 4 | 2 | 3500 | 1800 | 16.4 | 1.58 | 4.16 | . 136 137 | 2013 | 1 | 2 | 2 | 2900 | 1600 | 21.2 | 2.33 | 3.82 | . 163 164 | 2013 | 1 | 2 | 4 | 2300 | 2200 | 5.7 | 0.32 | 0.99 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 126 127 | 2013 | 0 | 4 | 5 | 12600 | 5400 | 3.1 | 0.48 | 3.43 | . 57 58 | 2013 | 0 | 2 | 1 | 3400 | 1300 | 6.5 | 0.85 | 1.36 | . 149 150 | 2013 | 0 | 3 | 2 | 4500 | 1900 | 3.7 | 0.98 | 0.68 | . 44 45 | 2013 | 0 | 4 | 2 | 4100 | 2500 | 3.4 | 0.36 | 1.04 | . 141 142 | 2013 | 0 | 3 | 4 | 3200 | 1900 | 1.6 | 0.02 | 0.49 | . 140 rows × 10 columns . b13.sample(frac=0.3) . id year buy age edu income exp co ad prod . 217 218 | 2013 | 0 | 3 | 1 | 2400 | 1500 | 6.6 | 0.44 | 1.14 | . 47 48 | 2013 | 0 | 3 | 1 | 3200 | 2500 | 11.3 | 2.10 | 1.51 | . 150 151 | 2013 | 0 | 4 | 1 | 10000 | 5300 | 14.6 | 5.40 | 9.20 | . 21 22 | 2013 | 0 | 3 | 1 | 4500 | 2400 | 17.0 | 2.74 | 4.91 | . 82 83 | 2013 | 0 | 2 | 1 | 1600 | 900 | 1.2 | 0.08 | 0.11 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 183 184 | 2013 | 1 | 2 | 1 | 1700 | 1100 | 2.5 | 0.20 | 0.23 | . 35 36 | 2013 | 0 | 3 | 2 | 6500 | 5200 | 6.2 | 2.11 | 1.92 | . 80 81 | 2013 | 0 | 3 | 1 | 4500 | 3600 | 3.7 | 0.92 | 0.75 | . 134 135 | 2013 | 0 | 4 | 3 | 6400 | 4300 | 6.6 | 0.28 | 3.95 | . 67 68 | 2013 | 0 | 2 | 1 | 2200 | 2000 | 14.4 | 0.85 | 2.32 | . 70 rows × 10 columns . b13.sample(frac=0.1) . id year buy age edu income exp co ad prod . 129 130 | 2013 | 1 | 5 | 4 | 7800 | 6100 | 17.3 | 6.94 | 6.56 | . 94 95 | 2013 | 0 | 2 | 1 | 1700 | 1100 | 9.0 | 0.47 | 1.06 | . 50 51 | 2013 | 0 | 2 | 3 | 4400 | 3400 | 8.7 | 0.77 | 3.05 | . 10 11 | 2013 | 0 | 3 | 1 | 4800 | 3800 | 13.1 | 1.93 | 4.36 | . 219 220 | 2013 | 0 | 3 | 3 | 5400 | 5300 | 2.8 | 0.40 | 1.11 | . 93 94 | 2013 | 0 | 4 | 1 | 5200 | 4300 | 5.4 | 0.93 | 1.88 | . 209 210 | 2013 | 0 | 4 | 1 | 10000 | 8900 | 11.5 | 5.06 | 6.44 | . 114 115 | 2013 | 0 | 4 | 2 | 4300 | 3700 | 0.7 | 0.09 | 0.22 | . 60 61 | 2013 | 0 | 3 | 2 | 4000 | 3200 | 7.2 | 0.18 | 2.70 | . 222 223 | 2013 | 1 | 3 | 1 | 3400 | 2400 | 11.1 | 1.37 | 2.40 | . 62 63 | 2013 | 0 | 4 | 3 | 11600 | 8700 | 6.0 | 2.56 | 4.40 | . 188 189 | 2013 | 0 | 4 | 1 | 9100 | 7800 | 13.7 | 0.57 | 11.89 | . 89 90 | 2013 | 0 | 3 | 2 | 3000 | 1800 | 7.6 | 0.65 | 1.63 | . 185 186 | 2013 | 0 | 3 | 2 | 4900 | 5300 | 1.3 | 0.27 | 0.36 | . 173 174 | 2013 | 0 | 2 | 1 | 1800 | 1400 | 6.0 | 0.53 | 0.55 | . 99 100 | 2013 | 1 | 3 | 1 | 6000 | 4700 | 27.1 | 9.59 | 6.67 | . 154 155 | 2013 | 0 | 3 | 1 | 1700 | 1500 | 12.0 | 0.30 | 1.74 | . 162 163 | 2013 | 0 | 5 | 1 | 1800 | 2100 | 4.4 | 0.27 | 0.52 | . 197 198 | 2013 | 0 | 4 | 4 | 4700 | 4800 | 5.0 | 0.44 | 1.91 | . 211 212 | 2013 | 0 | 4 | 2 | 1900 | 2900 | 6.3 | 0.12 | 1.07 | . 56 57 | 2013 | 0 | 4 | 2 | 5700 | 4400 | 5.6 | 0.88 | 2.31 | . 74 75 | 2013 | 0 | 3 | 1 | 4000 | 2500 | 18.5 | 1.21 | 6.19 | . 86 87 | 2013 | 0 | 3 | 1 | 3800 | 3300 | 8.9 | 1.90 | 1.48 | . b14.sample(frac=0.6) . id year buy age edu income exp co ad prod . 257 258 | 2014 | 0 | 4 | 1 | 2000 | 700 | 14.0 | 0.81 | 1.99 | . 463 464 | 2014 | 1 | 2 | 1 | 2100 | 1400 | 8.4 | 1.21 | 0.55 | . 248 249 | 2014 | 1 | 2 | 2 | 2400 | 1700 | 17.1 | 1.34 | 2.77 | . 271 272 | 2014 | 0 | 4 | 3 | 8200 | 4100 | 3.3 | 1.32 | 1.39 | . 404 405 | 2014 | 1 | 2 | 1 | 1600 | 1300 | 17.8 | 1.01 | 1.84 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 332 333 | 2014 | 0 | 5 | 2 | 15900 | 5400 | 2.8 | 1.07 | 3.38 | . 418 419 | 2014 | 0 | 5 | 2 | 24900 | 17000 | 7.8 | 4.27 | 15.15 | . 434 435 | 2014 | 1 | 2 | 3 | 4200 | 3200 | 19.9 | 2.71 | 5.65 | . 373 374 | 2014 | 0 | 4 | 1 | 2400 | 1600 | 7.0 | 0.76 | 0.92 | . 352 353 | 2014 | 1 | 3 | 1 | 1900 | 1400 | 16.6 | 0.62 | 2.53 | . 148 rows × 10 columns . b14.sample(frac=0.3) . id year buy age edu income exp co ad prod . 437 438 | 2014 | 1 | 2 | 1 | 1500 | 1200 | 11.3 | 0.07 | 1.62 | . 398 399 | 2014 | 1 | 2 | 2 | 2600 | 1800 | 9.7 | 0.89 | 1.63 | . 341 342 | 2014 | 0 | 2 | 1 | 2500 | 1600 | 7.1 | 1.31 | 0.47 | . 390 391 | 2014 | 0 | 3 | 3 | 2800 | 2400 | 2.6 | 0.12 | 0.61 | . 267 268 | 2014 | 0 | 3 | 4 | 2900 | 2800 | 11.0 | 1.84 | 1.35 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 477 478 | 2014 | 1 | 3 | 1 | 3300 | 2600 | 10.3 | 2.50 | 0.90 | . 376 377 | 2014 | 0 | 2 | 3 | 1700 | 2000 | 2.3 | 0.04 | 0.35 | . 240 241 | 2014 | 0 | 5 | 1 | 2700 | 1500 | 9.8 | 0.40 | 2.24 | . 264 265 | 2014 | 0 | 4 | 1 | 10000 | 8000 | 12.8 | 4.58 | 8.22 | . 426 427 | 2014 | 1 | 4 | 3 | 8600 | 7400 | 26.5 | 4.99 | 17.80 | . 74 rows × 10 columns . b14.sample(frac=0.1) . id year buy age edu income exp co ad prod . 437 438 | 2014 | 1 | 2 | 1 | 1500 | 1200 | 11.3 | 0.07 | 1.62 | . 346 347 | 2014 | 0 | 3 | 1 | 2300 | 1800 | 12.0 | 0.76 | 2.00 | . 413 414 | 2014 | 0 | 3 | 1 | 2100 | 1200 | 8.3 | 0.73 | 1.01 | . 320 321 | 2014 | 0 | 3 | 2 | 10500 | 7300 | 1.9 | 1.42 | 0.58 | . 240 241 | 2014 | 0 | 5 | 1 | 2700 | 1500 | 9.8 | 0.40 | 2.24 | . 300 301 | 2014 | 0 | 3 | 1 | 3300 | 3500 | 4.2 | 0.50 | 0.89 | . 440 441 | 2014 | 0 | 3 | 1 | 4000 | 2500 | 9.8 | 1.98 | 1.94 | . 426 427 | 2014 | 1 | 4 | 3 | 8600 | 7400 | 26.5 | 4.99 | 17.80 | . 267 268 | 2014 | 0 | 3 | 4 | 2900 | 2800 | 11.0 | 1.84 | 1.35 | . 451 452 | 2014 | 0 | 3 | 1 | 3600 | 2000 | 4.7 | 0.62 | 1.07 | . 349 350 | 2014 | 1 | 5 | 1 | 2800 | 1900 | 14.2 | 0.44 | 3.54 | . 290 291 | 2014 | 1 | 3 | 1 | 2900 | 2100 | 13.8 | 1.35 | 2.65 | . 254 255 | 2014 | 0 | 3 | 1 | 3500 | 3500 | 4.5 | 0.43 | 1.14 | . 411 412 | 2014 | 0 | 2 | 2 | 1600 | 1400 | 14.7 | 0.57 | 1.78 | . 364 365 | 2014 | 0 | 4 | 1 | 9500 | 5500 | 3.6 | 0.63 | 2.79 | . 239 240 | 2014 | 0 | 2 | 1 | 2600 | 1100 | 10.0 | 0.43 | 2.17 | . 288 289 | 2014 | 0 | 4 | 2 | 5100 | 5600 | 18.1 | 1.55 | 7.68 | . 270 271 | 2014 | 0 | 3 | 1 | 5400 | 3800 | 4.4 | 0.73 | 1.65 | . 387 388 | 2014 | 1 | 3 | 4 | 3300 | 2300 | 16.1 | 2.69 | 2.62 | . 334 335 | 2014 | 1 | 3 | 1 | 4900 | 2700 | 9.8 | 3.24 | 1.57 | . 366 367 | 2014 | 0 | 3 | 1 | 4400 | 5100 | 3.1 | 0.53 | 0.84 | . 257 258 | 2014 | 0 | 4 | 1 | 2000 | 700 | 14.0 | 0.81 | 1.99 | . 419 420 | 2014 | 0 | 2 | 1 | 3000 | 1200 | 8.2 | 0.15 | 2.31 | . 353 354 | 2014 | 0 | 2 | 2 | 1900 | 1400 | 4.3 | 0.36 | 0.46 | . 244 245 | 2014 | 0 | 2 | 3 | 3700 | 2500 | 14.2 | 0.20 | 5.05 | . b15.sample(frac=0.6) . id year buy age edu income exp co ad prod . 534 535 | 2015 | 0 | 4 | 4 | 4400 | 3500 | 1.7 | 0.35 | 0.39 | . 671 672 | 2015 | 0 | 4 | 4 | 18600 | 13300 | 3.6 | 2.40 | 4.29 | . 659 660 | 2015 | 0 | 2 | 1 | 1400 | 800 | 10.5 | 0.26 | 1.21 | . 517 518 | 2015 | 0 | 4 | 2 | 7300 | 6200 | 3.4 | 1.03 | 1.45 | . 596 597 | 2015 | 1 | 4 | 3 | 7100 | 4700 | 15.7 | 6.57 | 4.58 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 682 683 | 2015 | 0 | 3 | 1 | 5700 | 3100 | 10.5 | 1.14 | 4.84 | . 626 627 | 2015 | 1 | 2 | 2 | 2000 | 1200 | 4.5 | 0.29 | 0.61 | . 565 566 | 2015 | 0 | 3 | 2 | 2100 | 1200 | 18.3 | 0.49 | 3.35 | . 599 600 | 2015 | 0 | 3 | 2 | 8200 | 4800 | 0.8 | 0.47 | 0.19 | . 649 650 | 2015 | 1 | 4 | 2 | 2000 | 2300 | 16.9 | 0.38 | 3.00 | . 133 rows × 10 columns . b15.sample(frac=0.3) . id year buy age edu income exp co ad prod . 485 486 | 2015 | 0 | 3 | 1 | 6100 | 6700 | 5.7 | 0.56 | 2.91 | . 561 562 | 2015 | 0 | 2 | 1 | 1800 | 1400 | 6.5 | 0.53 | 0.64 | . 618 619 | 2015 | 0 | 3 | 1 | 2400 | 2000 | 4.5 | 0.22 | 0.86 | . 490 491 | 2015 | 0 | 2 | 1 | 2700 | 1300 | 14.4 | 1.02 | 2.87 | . 555 556 | 2015 | 0 | 4 | 3 | 1900 | 900 | 10.8 | 0.85 | 1.20 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 527 528 | 2015 | 1 | 4 | 1 | 7600 | 2200 | 6.1 | 2.15 | 2.48 | . 601 602 | 2015 | 0 | 4 | 3 | 9900 | 6600 | 2.3 | 0.83 | 1.45 | . 590 591 | 2015 | 0 | 3 | 2 | 3200 | 2800 | 4.9 | 0.42 | 1.15 | . 515 516 | 2015 | 1 | 5 | 1 | 5000 | 4500 | 11.2 | 2.02 | 3.58 | . 535 536 | 2015 | 0 | 2 | 1 | 2200 | 1800 | 9.7 | 0.55 | 1.58 | . 66 rows × 10 columns . b15.sample(frac=0.1) . id year buy age edu income exp co ad prod . 632 633 | 2015 | 0 | 2 | 2 | 2600 | 2300 | 4.5 | 0.07 | 1.10 | . 485 486 | 2015 | 0 | 3 | 1 | 6100 | 6700 | 5.7 | 0.56 | 2.91 | . 648 649 | 2015 | 1 | 3 | 1 | 3100 | 1800 | 11.7 | 1.70 | 1.93 | . 522 523 | 2015 | 0 | 3 | 1 | 1800 | 1700 | 12.9 | 0.98 | 1.34 | . 486 487 | 2015 | 0 | 5 | 1 | 5200 | 4900 | 3.2 | 1.15 | 0.51 | . 512 513 | 2015 | 0 | 3 | 1 | 11300 | 9000 | 2.6 | 0.99 | 1.95 | . 641 642 | 2015 | 1 | 4 | 2 | 4800 | 2700 | 8.6 | 1.20 | 2.93 | . 503 504 | 2015 | 0 | 2 | 1 | 1700 | 1200 | 6.7 | 0.16 | 0.98 | . 592 593 | 2015 | 0 | 2 | 2 | 1500 | 900 | 2.6 | 0.15 | 0.24 | . 569 570 | 2015 | 0 | 4 | 1 | 9600 | 5000 | 7.8 | 2.25 | 5.23 | . 546 547 | 2015 | 0 | 5 | 1 | 4700 | 3900 | 6.9 | 0.40 | 2.84 | . 608 609 | 2015 | 0 | 4 | 1 | 2700 | 2400 | 21.3 | 1.40 | 4.35 | . 479 480 | 2015 | 0 | 4 | 1 | 5500 | 2900 | 5.5 | 0.86 | 2.17 | . 553 554 | 2015 | 0 | 4 | 2 | 14500 | 10200 | 12.2 | 3.24 | 14.45 | . 637 638 | 2015 | 1 | 3 | 2 | 4000 | 3000 | 17.2 | 1.80 | 5.08 | . 611 612 | 2015 | 0 | 2 | 2 | 2100 | 1500 | 8.7 | 0.45 | 1.37 | . 559 560 | 2015 | 0 | 2 | 2 | 2000 | 1500 | 5.6 | 0.21 | 0.91 | . 547 548 | 2015 | 1 | 4 | 3 | 8800 | 5600 | 6.1 | 0.28 | 5.08 | . 638 639 | 2015 | 0 | 4 | 5 | 19000 | 18800 | 7.8 | 3.16 | 11.66 | . 691 692 | 2015 | 0 | 2 | 1 | 1600 | 1300 | 6.3 | 0.14 | 0.87 | . 671 672 | 2015 | 0 | 4 | 4 | 18600 | 13300 | 3.6 | 2.40 | 4.29 | . 554 555 | 2015 | 1 | 2 | 4 | 7000 | 7100 | 8.0 | 1.62 | 3.98 | . &#44284;&#51228; 2.6 . bn=bx1.groupby(bx1.age).mean().reset_index() #연령별 평균 . bn . age id year buy edu income exp co ad prod . 0 2 | 344.201970 | 2013.965517 | 0.384236 | 1.783251 | 2668.472906 | 1981.280788 | 10.249261 | 0.941773 | 1.749754 | . 1 3 | 348.308271 | 2013.973684 | 0.210526 | 1.631579 | 4048.496241 | 3050.751880 | 10.456015 | 1.454436 | 2.815639 | . 2 4 | 371.296970 | 2014.060606 | 0.187879 | 1.818182 | 6907.878788 | 4770.303030 | 9.844848 | 2.171697 | 4.559268 | . 3 5 | 326.712121 | 2013.878788 | 0.272727 | 1.666667 | 6359.090909 | 4689.393939 | 10.546970 | 2.288333 | 4.344242 | . from scipy import stats . from statsmodels.formula.api import ols from statsmodels.stats.anova import anova_lm model = ols(&#39;id ~ age&#39;,bn).fit() anova_lm(model) . df sum_sq mean_sq F PR(&gt;F) . age 1.0 | 43.456022 | 43.456022 | 0.08993 | 0.792563 | . Residual 2.0 | 966.438523 | 483.219262 | NaN | NaN | . model = ols(&#39;year ~ age&#39;,bn).fit() anova_lm(model) . df sum_sq mean_sq F PR(&gt;F) . age 1.0 | 0.001501 | 0.001501 | 0.199328 | 0.69895 | . Residual 2.0 | 0.015061 | 0.007531 | NaN | NaN | . model = ols(&#39;buy ~ age&#39;,bn).fit() anova_lm(model) . df sum_sq mean_sq F PR(&gt;F) . age 1.0 | 0.006379 | 0.006379 | 0.759006 | 0.475499 | . Residual 2.0 | 0.016808 | 0.008404 | NaN | NaN | . model = ols(&#39;edu ~ age&#39;,bn).fit() anova_lm(model) . df sum_sq mean_sq F PR(&gt;F) . age 1.0 | 0.001331 | 0.001331 | 0.116362 | 0.765518 | . Residual 2.0 | 0.022875 | 0.011438 | NaN | NaN | . model = ols(&#39;income ~ age&#39;,bn).fit() anova_lm(model) . df sum_sq mean_sq F PR(&gt;F) . age 1.0 | 9.703968e+06 | 9.703968e+06 | 9.135401 | 0.094245 | . Residual 2.0 | 2.124475e+06 | 1.062238e+06 | NaN | NaN | . model = ols(&#39;exp ~ age&#39;,bn).fit() anova_lm(model) . df sum_sq mean_sq F PR(&gt;F) . age 1.0 | 4.845109e+06 | 4.845109e+06 | 15.354464 | 0.059385 | . Residual 2.0 | 6.311010e+05 | 3.155505e+05 | NaN | NaN | . model = ols(&#39;co ~ age&#39;,bn).fit() anova_lm(model) . df sum_sq mean_sq F PR(&gt;F) . age 1.0 | 0.003975 | 0.003975 | 0.027561 | 0.883409 | . Residual 2.0 | 0.288450 | 0.144225 | NaN | NaN | . model = ols(&#39;ad ~ age&#39;,bn).fit() anova_lm(model) . df sum_sq mean_sq F PR(&gt;F) . age 1.0 | 1.131424 | 1.131424 | 31.591501 | 0.030226 | . Residual 2.0 | 0.071628 | 0.035814 | NaN | NaN | . model = ols(&#39;prod ~ age&#39;,bn).fit() anova_lm(model) . df sum_sq mean_sq F PR(&gt;F) . age 1.0 | 4.538277 | 4.538277 | 11.978876 | 0.074296 | . Residual 2.0 | 0.757713 | 0.378857 | NaN | NaN | . p-값이 0.05보다 작으면 유의미한 차이가 있다. 분산분석 실행 결과, ad와 age 사이의 p-값만 0.05보다 작으므로 유의미한 것을 알 수 있다. . import statsmodels.api as sm import statsmodels.formula.api as smf . model = smf.ols(formula = &#39;income ~ id + year + buy + age + edu + exp + co + ad + prod&#39;, data = bx1) result = model.fit() result.summary() . OLS Regression Results Dep. Variable: income | R-squared: 0.863 | . Model: OLS | Adj. R-squared: 0.862 | . Method: Least Squares | F-statistic: 483.6 | . Date: Wed, 23 Mar 2022 | Prob (F-statistic): 6.74e-291 | . Time: 02:20:50 | Log-Likelihood: -6007.9 | . No. Observations: 699 | AIC: 1.204e+04 | . Df Residuals: 689 | BIC: 1.208e+04 | . Df Model: 9 | | . Covariance Type: nonrobust | | . | coef std err t P&gt;|t| [0.025 0.975] . Intercept 2.29e+05 | 3.74e+05 | 0.613 | 0.540 | -5.05e+05 | 9.63e+05 | . id 0.6972 | 0.741 | 0.940 | 0.347 | -0.758 | 2.153 | . year -113.1872 | 185.628 | -0.610 | 0.542 | -477.652 | 251.278 | . buy 86.7623 | 128.299 | 0.676 | 0.499 | -165.141 | 338.665 | . age 146.4197 | 59.775 | 2.450 | 0.015 | 29.057 | 263.783 | . edu 178.8084 | 56.229 | 3.180 | 0.002 | 68.408 | 289.209 | . exp 0.7844 | 0.032 | 24.363 | 0.000 | 0.721 | 0.848 | . co -179.1309 | 11.651 | -15.375 | 0.000 | -202.006 | -156.256 | . ad 444.4350 | 33.612 | 13.222 | 0.000 | 378.441 | 510.429 | . prod 338.7486 | 27.602 | 12.273 | 0.000 | 284.554 | 392.943 | . Omnibus: 461.106 | Durbin-Watson: 1.898 | . Prob(Omnibus): 0.000 | Jarque-Bera (JB): 16793.720 | . Skew: 2.401 | Prob(JB): 0.00 | . Kurtosis: 26.527 | Cond. No. 3.34e+07 | . Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 3.34e+07. This might indicate that there arestrong multicollinearity or other numerical problems. import statsmodels.api as sm logis = sm.Logit.from_formula(&#39;buy ~ id+year+age+edu+income+exp+co+ad+prod&#39;, bx1).fit() logis.summary() . Optimization terminated successfully. Current function value: 0.453782 Iterations 11 . Logit Regression Results Dep. Variable: buy | No. Observations: 699 | . Model: Logit | Df Residuals: 689 | . Method: MLE | Df Model: 9 | . Date: Wed, 23 Mar 2022 | Pseudo R-squ.: 0.2107 | . Time: 02:32:06 | Log-Likelihood: -317.19 | . converged: True | LL-Null: -401.88 | . Covariance Type: nonrobust | LLR p-value: 8.345e-32 | . | coef std err z P&gt;|z| [0.025 0.975] . Intercept 504.8943 | 743.679 | 0.679 | 0.497 | -952.689 | 1962.478 | . id 0.0016 | 0.001 | 1.101 | 0.271 | -0.001 | 0.004 | . year -0.2516 | 0.369 | -0.681 | 0.496 | -0.976 | 0.473 | . age -0.1786 | 0.121 | -1.475 | 0.140 | -0.416 | 0.059 | . edu 0.4181 | 0.108 | 3.876 | 0.000 | 0.207 | 0.629 | . income -7.439e-05 | 9.22e-05 | -0.807 | 0.420 | -0.000 | 0.000 | . exp -0.0004 | 0.000 | -3.651 | 0.000 | -0.001 | -0.000 | . co 0.0736 | 0.030 | 2.452 | 0.014 | 0.015 | 0.132 | . ad 0.4438 | 0.104 | 4.261 | 0.000 | 0.240 | 0.648 | . prod 0.0451 | 0.075 | 0.601 | 0.548 | -0.102 | 0.192 | . P&gt;|z| 부분을 보면 유의확률을 알 수 있다, 독립변수의 유의확률이 0.05보다 작으면 독립변수가 종속변수에 영향을 미치는 것이 유의미하다고 본다. 따라서 edu, exp, co, ad는 buy에 유의미하게 영향을 미친다. .",
            "url": "https://suuiq.github.io/blue/2022/03/22/Untitled.html",
            "relUrl": "/2022/03/22/Untitled.html",
            "date": " • Mar 22, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://suuiq.github.io/blue/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://suuiq.github.io/blue/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "전북대학교 통계학과 3학년 .",
          "url": "https://suuiq.github.io/blue/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://suuiq.github.io/blue/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}